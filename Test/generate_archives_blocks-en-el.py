import os
import json
from bs4 import BeautifulSoup
from datetime import datetime
import locale
import shutil

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
NEW_HTML_DIR = os.path.join(BASE_DIR, "New-html")

ARCHIVE_PAGES = {
    "el": "sparkethos-archives-el.html",
    "en": "sparkethos-archives-en.html",
}

def format_date(date_obj, lang):
    if lang == "el":
        locale.setlocale(locale.LC_TIME, "el_GR.UTF-8")
        return date_obj.strftime("%d %B %Y")
    else:
        locale.setlocale(locale.LC_TIME, "en_US.UTF-8")
        return date_obj.strftime("%B %d, %Y")

def default_icon(lang):
    return "ğŸŒ"  # default icon Î³Î¹Î± Î½Î­Î± Î¬ÏÎ¸ÏÎ±

# -------------------------------
# 1. Î¦ÏŒÏÏ„Ï‰ÏƒÎ· archive pages
# -------------------------------
archive_soups = {}
existing_blocks = {"el": {}, "en": {}}

for lang, archive_file in ARCHIVE_PAGES.items():
    path = os.path.join(BASE_DIR, archive_file)
    if not os.path.exists(path):
        raise FileNotFoundError(f"âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Ï„Î¿ {archive_file} ÏƒÏ„Î¿ root")

    # backup
    shutil.copy(path, path + ".bak")

    with open(path, "r", encoding="utf-8") as f:
        soup = BeautifulSoup(f.read(), "html.parser")

    archive_soups[lang] = soup

    section = soup.find("section", id="articles")
    if not section:
        raise RuntimeError(f"âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ <section id='articles'> ÏƒÏ„Î¿ {archive_file}")

    for div in section.find_all("div", class_="link-container"):
        a = div.find("a", href=True)
        if a:
            existing_blocks[lang][a["href"]] = div

# -------------------------------
# 2. Î£ÎºÎ±Î½Î¬ÏÎ¹ÏƒÎ¼Î± Î½Î­Ï‰Î½ Î¬ÏÎ¸ÏÏ‰Î½ Î±Ï€ÏŒ New-html
# -------------------------------
if not os.path.exists(NEW_HTML_DIR):
    raise FileNotFoundError(f"âŒ ÎŸ Ï†Î¬ÎºÎµÎ»Î¿Ï‚ New-html Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ")

for file in os.listdir(NEW_HTML_DIR):
    if not file.endswith(".html"):
        continue

    file_path = os.path.join(NEW_HTML_DIR, file)
    with open(file_path, "r", encoding="utf-8") as f:
        soup = BeautifulSoup(f.read(), "html.parser")

    lang = soup.html.get("lang", "en")
    if lang not in ARCHIVE_PAGES:
        continue

    title = soup.title.get_text(strip=True)

    keywords_tag = soup.find("meta", {"name": "keywords"})
    keywords = keywords_tag["content"] if keywords_tag else ""

    canonical = soup.find("link", {"rel": "canonical"})
    href = canonical["href"].split("/")[-1] if canonical else file

    json_ld = soup.find("script", {"type": "application/ld+json"})
    article_data = json.loads(json_ld.string)

    date_obj = datetime.fromisoformat(article_data["datePublished"])
    data_date = date_obj.strftime("%Y-%m-%d")
    display_date = format_date(date_obj, lang)

    section = archive_soups[lang].find("section", id="articles")

    # --------------------------------------------
    # Î‘) Î¥Î Î‘Î¡Î§ÎŸÎ Î¬ÏÎ¸ÏÎ¿ â†’ update metadata, Ï‡Ï‰ÏÎ¯Ï‚ Î±Î»Î»Î±Î³Î® icon
    # --------------------------------------------
    if href in existing_blocks[lang]:
        block = existing_blocks[lang][href]
        block["data-title"] = title
        block["data-date"] = data_date
        block["data-tags"] = keywords

        pub_date = block.find("span", class_="pub-date")
        if pub_date:
            pub_date.string = display_date

        continue

    # --------------------------------------------
    # Î’) ÎÎ•ÎŸ Î¬ÏÎ¸ÏÎ¿ â†’ Ï€ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Î¼Îµ default icon Î¼ÏŒÎ½Î¿ Î±Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹
    # --------------------------------------------
    new_block = BeautifulSoup(f'''
<div class="link-container"
     data-title="{title}"
     data-date="{data_date}"
     data-tags="{keywords}">
  <a href="{href}" target="_blank" class="link-button">
    <span class="icon">{default_icon(lang)}</span>{title}
  </a>
  <span class="pub-date">{display_date}</span>
</div>
''', "html.parser")

    # Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® ÏƒÏ„Î¿ top Ï„Î¿Ï… section
    section.insert(0, new_block)

    print(f"âš¡ ÎÎ­Î¿ Î¬ÏÎ¸ÏÎ¿ Ï€ÏÎ¿ÏƒÏ„Î­Î¸Î·ÎºÎµ: {file}")

# -------------------------------
# 3. Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· archive pages
# -------------------------------
for lang, archive_file in ARCHIVE_PAGES.items():
    save_path = os.path.join(BASE_DIR, archive_file)
    with open(save_path, "w", encoding="utf-8") as f:
        f.write(archive_soups[lang].prettify())

    print(f"âœ… Î•Î½Î·Î¼ÎµÏÏÎ¸Î·ÎºÎµ: {archive_file}")

print("ğŸ¯ ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ: auto-icon + metadata sync (Î¼ÏŒÎ½Î¿ Î±Ï€ÏŒ New-html).")

