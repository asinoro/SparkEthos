import os
import json
import shutil
import locale
from datetime import datetime
from bs4 import BeautifulSoup

# =========================
# CONFIG
# =========================
DRY_RUN = False   # ğŸ” True = Î´ÎµÎ½ Î³ÏÎ¬Ï†ÎµÎ¹ Î±ÏÏ‡ÎµÎ¯Î± | False = ÎºÎ±Î½Î¿Î½Î¹ÎºÎ® ÎµÎ³Î³ÏÎ±Ï†Î®
DEFAULT_ICON = "ğŸŒ"

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = os.path.dirname(SCRIPT_DIR)   # SparkEthos root
NEW_HTML_DIR = SCRIPT_DIR                # Ï„Î± Î½Î­Î± Î¬ÏÎ¸ÏÎ± ÎµÎ¯Î½Î±Î¹ ÎµÎ´Ï

ARCHIVE_PAGES = {
    "el": "sparkethos-archives-el.html",
    "en": "sparkethos-archives-en.html",
}

# =========================
# HELPERS
# =========================
def format_date(date_obj, lang):
    try:
        if lang == "el":
            locale.setlocale(locale.LC_TIME, "el_GR.UTF-8")
            return date_obj.strftime("%d %B %Y")
        else:
            locale.setlocale(locale.LC_TIME, "en_US.UTF-8")
            return date_obj.strftime("%B %d, %Y")
    except locale.Error:
        # fallback Î±Î½ Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ locales
        return date_obj.strftime("%Y-%m-%d")

def log(msg):
    print(msg)

def smart_icon(title, keywords=""):
    text = f"{title} {keywords}".lower()

    ICON_MAP = {
        "ai": "ğŸ§ ",
        "artificial intelligence": "ğŸ§ ",
        "Ï„ÎµÏ‡Î½Î·Ï„Î® Î½Î¿Î·Î¼Î¿ÏƒÏÎ½Î·": "ğŸ§ ",
        "ethic": "âš–ï¸",
        "Î·Î¸Î¹ÎºÎ®": "âš–ï¸",
        "philosophy": "ğŸ­",
        "Ï†Î¹Î»Î¿ÏƒÎ¿Ï†": "ğŸ­",
        "control": "ğŸ§¯",
        "Î­Î»ÎµÎ³Ï‡Î¿Ï‚": "ğŸ§¯",
        "paradox": "ğŸ§©",
        "Ï€Î±ÏÎ¬Î´Î¿Î¾Î¿": "ğŸ§©",
        "conscious": "ğŸ§¬",
        "ÏƒÏ…Î½ÎµÎ¯Î´Î·ÏƒÎ·": "ğŸ§¬",
        "security": "ğŸŸ¥",
        "Î‘ÏƒÏ†Î¬Î»ÎµÎ¹Î±": "ğŸŸ¥",
        "Î ÏŒÎ»ÎµÎ¼Î¿Ï‚": "ğŸŸ¥",
        "war": "ğŸŸ¥",
        "ÎºÏ…Î²ÎµÏÎ½Î¿ÎµÏ€Î¯Î¸ÎµÏƒÎ·": "ğŸŸ¥",
        "cyberattack": "ğŸŸ¥",
        "future": "ğŸš€",
        "Î¼Î­Î»Î»Î¿Î½": "ğŸš€",
        "logic": "ğŸ”¹",
        "Î»Î¿Î³Î¹ÎºÎ®": "ğŸ”¹",
    }

    for key, icon in ICON_MAP.items():
        if key in text:
            return icon

    return "ğŸŒ"   # fallback

# =========================
# 1. Î¦ÎŸÎ¡Î¤Î©Î£Î— ARCHIVES
# =========================
archive_soups = {}
existing_blocks = {"el": {}, "en": {}}

for lang, archive_file in ARCHIVE_PAGES.items():
    path = os.path.join(ROOT_DIR, archive_file)
    if not os.path.exists(path):
        raise FileNotFoundError(f"âŒ Î›ÎµÎ¯Ï€ÎµÎ¹ Ï„Î¿ {archive_file}")

    if not DRY_RUN:
        shutil.copy(path, path + ".bak")

    with open(path, "r", encoding="utf-8") as f:
        soup = BeautifulSoup(f.read(), "html.parser")

    archive_soups[lang] = soup

    section = soup.find("section", id="articles")
    if not section:
        raise RuntimeError(f"âŒ Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ <section id='articles'> ÏƒÏ„Î¿ {archive_file}")

    for div in section.find_all("div", class_="link-container"):
        a = div.find("a", href=True)
        if a:
            existing_blocks[lang][a["href"]] = div

# =========================
# 2. Î£ÎšÎ‘ÎÎ‘Î¡Î™Î£ÎœÎ‘ ÎÎ•Î©Î HTML
# =========================
for file in os.listdir(NEW_HTML_DIR):
    if not file.endswith(".html"):
        continue

    file_path = os.path.join(NEW_HTML_DIR, file)
    with open(file_path, "r", encoding="utf-8") as f:
        soup = BeautifulSoup(f.read(), "html.parser")

    lang = soup.html.get("lang", "en")
    if lang not in ARCHIVE_PAGES:
        continue

    title = soup.title.get_text(strip=True)

    keywords_tag = soup.find("meta", {"name": "keywords"})
    keywords = keywords_tag["content"] if keywords_tag else ""

    canonical = soup.find("link", {"rel": "canonical"})
    href = canonical["href"].split("/")[-1] if canonical else file

    json_ld = soup.find("script", {"type": "application/ld+json"})
    if not json_ld:
        log(f"âš ï¸ Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ· (Î´ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ JSON-LD): {file}")
        continue

    article_data = json.loads(json_ld.string)
    date_obj = datetime.fromisoformat(article_data["datePublished"])
    data_date = date_obj.strftime("%Y-%m-%d")
    display_date = format_date(date_obj, lang)

    section = archive_soups[lang].find("section", id="articles")

    # ---------------------------
    # Î‘) Î¥Î Î‘Î¡Î§ÎŸÎ â†’ update metadata
    # ---------------------------
    if href in existing_blocks[lang]:
        block = existing_blocks[lang][href]

        log(f"ğŸ” UPDATE metadata: {href}")

        if not DRY_RUN:
            block["data-title"] = title
            block["data-date"] = data_date
            block["data-tags"] = keywords

            pub_date = block.find("span", class_="pub-date")
            if pub_date:
                pub_date.string = display_date

        continue

    # ---------------------------
    # Î’) ÎÎ•ÎŸ â†’ auto-icon
    # ---------------------------
    log(f"â• NEW article: {href}")

    new_block = BeautifulSoup(f"""
<div class="link-container"
     data-title="{title}"
     data-date="{data_date}"
     data-tags="{keywords}">
  <a href="{href}" target="_blank" class="link-button">
    <span class="icon">{smart_icon(title, keywords)}</span>{title}
  </a>
  <span class="pub-date">{display_date}</span>
</div>
""", "html.parser")

    if not DRY_RUN:
        section.insert(0, new_block)

# =========================
# 3. Î‘Î ÎŸÎ˜Î—ÎšÎ•Î¥Î£Î—
# =========================
for lang, archive_file in ARCHIVE_PAGES.items():
    path = os.path.join(ROOT_DIR, archive_file)

    if DRY_RUN:
        log(f"ğŸ§ª DRY-RUN: Î”ÎµÎ½ Î³ÏÎ¬Ï†Ï„Î·ÎºÎµ Ï„Î¿ {archive_file}")
    else:
        with open(path, "w", encoding="utf-8") as f:
            f.write(archive_soups[lang].prettify())
        log(f"âœ… Î•Î½Î·Î¼ÎµÏÏÎ¸Î·ÎºÎµ: {archive_file}")

log("ğŸ¯ ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ (auto-icon + metadata sync)")
